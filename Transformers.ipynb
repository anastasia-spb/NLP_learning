{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b8dc2db",
   "metadata": {},
   "source": [
    "## Text Classification\n",
    "\n",
    "-----------\n",
    "https://www.kaggle.com/competitions/nlp-txt-classification\n",
    "\n",
    "The goal is to classify tweets. There are 5 categories: Extremely Negative,  Negative, Neutral, Positive, Extremely Positive.\n",
    "\n",
    "This falls into the \"Classifying whole sentences\" category of common NLP tasks.\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e237e0",
   "metadata": {},
   "source": [
    "Let's start with import of modules, we are going to use and setting `cuda` device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4637e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b788e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Cuda maintenance\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Torch device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1312e423",
   "metadata": {},
   "source": [
    "### 0. Read and manually preprocess input data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49533bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv')  \n",
    "df_test = pd.read_csv('../data/test.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2707e187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>41152</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>41153</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>41154</td>\n",
       "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41157</th>\n",
       "      <td>41155</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41158</th>\n",
       "      <td>41156</td>\n",
       "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               Text  \\\n",
       "41154      41152  Airline pilots offering to stock supermarket s...   \n",
       "41155      41153  Response to complaint not provided citing COVI...   \n",
       "41156      41154  You know itÂs getting tough when @KameronWild...   \n",
       "41157      41155  Is it wrong that the smell of hand sanitizer i...   \n",
       "41158      41156  @TartiiCat Well new/used Rift S are going for ...   \n",
       "\n",
       "                Sentiment  \n",
       "41154             Neutral  \n",
       "41155  Extremely Negative  \n",
       "41156            Positive  \n",
       "41157             Neutral  \n",
       "41158            Negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db90dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        advice Talk to your neighbours family to excha...\n",
       "2        Coronavirus Australia: Woolworths to give elde...\n",
       "3        My food stock is not the only one which is emp...\n",
       "5        As news of the regionÂs first confirmed COVID...\n",
       "6        Cashier at grocery store was sharing his insig...\n",
       "                               ...                        \n",
       "41142    Good News! \\r\\r\\nWe'll Soon Announce Our High ...\n",
       "41147    How exactly are we going to re-open New York C...\n",
       "41148    #Gold prices rose to a more than 7-year high t...\n",
       "41152    I never that weÂd be in a situation &amp; wor...\n",
       "41156    You know itÂs getting tough when @KameronWild...\n",
       "Name: Text, Length: 11422, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of Positive tweets:\n",
    "df[df.Sentiment == 'Positive'].Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5782dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...\n",
       "7        Was at the supermarket today. Didn't buy toile...\n",
       "10       All month there hasn't been crowding in the su...\n",
       "16       ????? ????? ????? ????? ??\\r\\r\\n?????? ????? ?...\n",
       "17       @eyeonthearctic 16MAR20 Russia consumer survei...\n",
       "                               ...                        \n",
       "41143    #Coronavirus ?? ????? ??? ????? ?? ??? ???????...\n",
       "41145    https://t.co/8s4vKvcO1r #5gtowers?? #EcuadorUn...\n",
       "41146    @_Sunrise_SV @Gamzap @NPR What does not having...\n",
       "41154    Airline pilots offering to stock supermarket s...\n",
       "41157    Is it wrong that the smell of hand sanitizer i...\n",
       "Name: Text, Length: 7711, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of Neutral tweets:\n",
    "df[df.Sentiment == 'Neutral'].Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57313432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9        For corona prevention,we should stop to buy th...\n",
       "24       @10DowningStreet @grantshapps what is being do...\n",
       "26       In preparation for higher demand and a potenti...\n",
       "28       Do you see malicious price increases in NYC? T...\n",
       "30       There Is of in the Country  The more empty she...\n",
       "                               ...                        \n",
       "41129    Today at the grocery store I saw someone getti...\n",
       "41133    In every human affliction there are  gainers a...\n",
       "41149    YÂall really shitting that much more at home?...\n",
       "41151    Still shocked by the number of #Toronto superm...\n",
       "41158    @TartiiCat Well new/used Rift S are going for ...\n",
       "Name: Text, Length: 9917, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of Negative tweets:\n",
    "df[df.Sentiment == 'Negative'].Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4464c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Positive', 'Extremely Negative', 'Negative',\n",
       "       'Extremely Positive', nan], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df[\"Sentiment\"].unique()\n",
    "num_labels = len(df[\"Sentiment\"].unique())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea875228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7d73fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...      0\n",
       "1  advice Talk to your neighbours family to excha...      1\n",
       "2  Coronavirus Australia: Woolworths to give elde...      1\n",
       "3  My food stock is not the only one which is emp...      1\n",
       "4  Me, ready to go at supermarket during the #COV...      2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna().drop_duplicates().reset_index(drop=True)\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "df.rename(columns={\"Sentiment\": \"label\"}, inplace=True)\n",
    "df.rename(columns={\"Text\": \"text\"}, inplace=True)\n",
    "df = df.astype({\"text\": str}, {\"label\": str})\n",
    "\n",
    "df[\"label\"] = df[\"label\"].apply(lambda x: np.where(labels == x)[0][0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18fd0a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>Meanwhile In A Supermarket in Israel -- People...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>Did you panic buy a lot of non-perishable item...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>Asst Prof of Economics @cconces was on @NBCPhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>Gov need to do somethings instead of biar je r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>I and @ForestandPaper members are committed to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "3793  Meanwhile In A Supermarket in Israel -- People...\n",
       "3794  Did you panic buy a lot of non-perishable item...\n",
       "3795  Asst Prof of Economics @cconces was on @NBCPhi...\n",
       "3796  Gov need to do somethings instead of biar je r...\n",
       "3797  I and @ForestandPaper members are committed to..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.astype({\"Text\": str})\n",
    "df_test.rename(columns={\"Text\": \"text\"}, inplace=True)\n",
    "df_test = df_test.drop([\"id\"], axis=1)\n",
    "\n",
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5554282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff62fd7e",
   "metadata": {},
   "source": [
    "### 1. Select tokenizer and pretrained model\n",
    "\n",
    "----------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0d1d86",
   "metadata": {},
   "source": [
    "For this task we will need encoder-only model, since we only need to understand the input.\n",
    "Let's use **distilbert-base-uncased-finetuned-sst-2-english** model for classification.\n",
    "Description and hyper-parameters can be found here: https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\n",
    "\n",
    "<br/>\n",
    "\n",
    "I have also tried to use https://huggingface.co/digitalepidemiologylab/covid-twitter-bert-v2-mnli model, however after loading it to GPU alongside with data, there were not enough space\n",
    "to perform training\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fadc259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0b3eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "config = AutoConfig.from_pretrained(checkpoint, num_labels=num_labels)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, \n",
    "                                                           config=config, \n",
    "                                                           ignore_mismatched_sizes=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84d83ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "005e4459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, eval_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_dataset = Dataset.from_dict(train_df.to_dict('list'))\n",
    "eval_dataset = Dataset.from_dict(eval_df.to_dict('list'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aff350d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def tokenize_function(examples, device):\n",
    "    return tokenizer(examples[\"text\"],\n",
    "                     padding=True,\n",
    "                     truncation=True,\n",
    "                     return_tensors=\"pt\").to(device)\n",
    "\n",
    "tokenize_function_on_device = lambda examples: tokenize_function(examples, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef0c484f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327d957e06854d7d9025ca3673f3a010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ea4c14f32b4a589365a408ebc0f595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# speed up the map function by setting batched=True\n",
    "# to process multiple elements of the dataset at once\n",
    "tokenized_train_dataset = train_dataset.map(\n",
    "    tokenize_function_on_device, batched=True\n",
    ")\n",
    "\n",
    "tokenized_eval_dataset = eval_dataset.map(\n",
    "    tokenize_function_on_device, batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4608ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "# Data Collator is used to create a batch of examples.\n",
    "# It will dynamically pad text to the length of the longest element in a batch\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad709b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1) \n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48a479ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Fine-tuning hyper-parameters: https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir, # where the model predictions and checkpoints will be written.     \n",
    "    evaluation_strategy=\"epoch\", # evaluation is done at the end of each epoch\n",
    "    num_train_epochs=5,\n",
    "    #learning_rate=5e-5, # same as default. With 1e-5 accuracy on third epoch is 0.8\n",
    "    per_device_train_batch_size=16, # If we increase bacth size to 32, then face \"RuntimeError: CUDA error: out of memory\"\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500, # number of steps used for a linear warmup\n",
    "    weight_decay=0.01, # to reduce overfitting\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model, # pretrained model\n",
    "    training_args, # arguments to tweak for training\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    data_collator=data_collator, # the function to use to form a batch from a list of elements of train_dataset or eval_dataset\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cda9e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/nastya/anaconda3/envs/env_torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 32924\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10290\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10290' max='10290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10290/10290 33:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.548900</td>\n",
       "      <td>0.563454</td>\n",
       "      <td>0.787268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.385200</td>\n",
       "      <td>0.482872</td>\n",
       "      <td>0.827238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.446607</td>\n",
       "      <td>0.860041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160500</td>\n",
       "      <td>0.499279</td>\n",
       "      <td>0.876929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.098100</td>\n",
       "      <td>0.620188</td>\n",
       "      <td>0.869518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-2000\n",
      "Configuration saved in ./results/checkpoint-2000/config.json\n",
      "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-2000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8231\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./results/checkpoint-2500\n",
      "Configuration saved in ./results/checkpoint-2500/config.json\n",
      "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-3000\n",
      "Configuration saved in ./results/checkpoint-3000/config.json\n",
      "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-3000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-3500\n",
      "Configuration saved in ./results/checkpoint-3500/config.json\n",
      "Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-3500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-4000\n",
      "Configuration saved in ./results/checkpoint-4000/config.json\n",
      "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-4000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8231\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./results/checkpoint-4500\n",
      "Configuration saved in ./results/checkpoint-4500/config.json\n",
      "Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-4500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-5000\n",
      "Configuration saved in ./results/checkpoint-5000/config.json\n",
      "Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-5000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-5500\n",
      "Configuration saved in ./results/checkpoint-5500/config.json\n",
      "Model weights saved in ./results/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-5500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-6000\n",
      "Configuration saved in ./results/checkpoint-6000/config.json\n",
      "Model weights saved in ./results/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-6000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8231\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./results/checkpoint-6500\n",
      "Configuration saved in ./results/checkpoint-6500/config.json\n",
      "Model weights saved in ./results/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-6500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-7000\n",
      "Configuration saved in ./results/checkpoint-7000/config.json\n",
      "Model weights saved in ./results/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-7000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-7500\n",
      "Configuration saved in ./results/checkpoint-7500/config.json\n",
      "Model weights saved in ./results/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-7500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-8000\n",
      "Configuration saved in ./results/checkpoint-8000/config.json\n",
      "Model weights saved in ./results/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-8000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8231\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./results/checkpoint-8500\n",
      "Configuration saved in ./results/checkpoint-8500/config.json\n",
      "Model weights saved in ./results/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-8500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-9000\n",
      "Configuration saved in ./results/checkpoint-9000/config.json\n",
      "Model weights saved in ./results/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-9000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-9500\n",
      "Configuration saved in ./results/checkpoint-9500/config.json\n",
      "Model weights saved in ./results/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-9500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-10000\n",
      "Configuration saved in ./results/checkpoint-10000/config.json\n",
      "Model weights saved in ./results/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-10000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 8231\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10290, training_loss=0.34690826516109724, metrics={'train_runtime': 2025.6569, 'train_samples_per_second': 81.267, 'train_steps_per_second': 5.08, 'total_flos': 1.0214015704462224e+16, 'train_loss': 0.34690826516109724, 'epoch': 5.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f7cfe5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9262fa195ac84c8e941a8378046d2174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = Dataset.from_dict(df_test.to_dict('list'))\n",
    "tokenized_test_dataset = test_dataset.map(\n",
    "    tokenize_function_on_device, batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69ad3bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 3798\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56223812",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities = torch.nn.functional.softmax(torch.from_numpy(predictions.predictions),\n",
    "                                                      dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73d75615",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "for prediction in predicted_probabilities:\n",
    "    max_idx = prediction.argmax().item()\n",
    "    predicted_labels.append(labels[max_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2c14925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>787bc85b-20d4-46d8-84a0-562a2527f684</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17e934cd-ba94-4d4f-9ac0-ead202abe241</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5914534b-2b0f-4de8-bb8a-e25587697e0d</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cdf06cfe-29ae-48ee-ac6d-be448103ba45</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aff63979-0256-4fb9-a2d9-86a3d3ca5470</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id Sentiment\n",
       "0  787bc85b-20d4-46d8-84a0-562a2527f684   Neutral\n",
       "1  17e934cd-ba94-4d4f-9ac0-ead202abe241   Neutral\n",
       "2  5914534b-2b0f-4de8-bb8a-e25587697e0d   Neutral\n",
       "3  cdf06cfe-29ae-48ee-ac6d-be448103ba45   Neutral\n",
       "4  aff63979-0256-4fb9-a2d9-86a3d3ca5470   Neutral"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f38dc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>787bc85b-20d4-46d8-84a0-562a2527f684</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17e934cd-ba94-4d4f-9ac0-ead202abe241</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5914534b-2b0f-4de8-bb8a-e25587697e0d</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cdf06cfe-29ae-48ee-ac6d-be448103ba45</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aff63979-0256-4fb9-a2d9-86a3d3ca5470</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b130f7fb-7048-48e6-a8af-57bb56ac1e27</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>db72c632-8719-4847-b7f2-a89af05e1504</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>e45239d8-4dcf-4685-a955-a9a08ca829ee</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2854b1b2-5a41-4002-90d3-17fe77a3a78e</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ff9be7e1-81a9-4c07-beda-4fee9a923f5e</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id           Sentiment\n",
       "0  787bc85b-20d4-46d8-84a0-562a2527f684  Extremely Negative\n",
       "1  17e934cd-ba94-4d4f-9ac0-ead202abe241            Positive\n",
       "2  5914534b-2b0f-4de8-bb8a-e25587697e0d  Extremely Positive\n",
       "3  cdf06cfe-29ae-48ee-ac6d-be448103ba45            Negative\n",
       "4  aff63979-0256-4fb9-a2d9-86a3d3ca5470             Neutral\n",
       "5  b130f7fb-7048-48e6-a8af-57bb56ac1e27             Neutral\n",
       "6  db72c632-8719-4847-b7f2-a89af05e1504            Positive\n",
       "7  e45239d8-4dcf-4685-a955-a9a08ca829ee             Neutral\n",
       "8  2854b1b2-5a41-4002-90d3-17fe77a3a78e  Extremely Negative\n",
       "9  ff9be7e1-81a9-4c07-beda-4fee9a923f5e  Extremely Positive"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['Sentiment'] = predicted_labels\n",
    "sample_submission.to_csv('test_submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a38347d",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "Accuracy on test dataset: 0.861\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a51307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
